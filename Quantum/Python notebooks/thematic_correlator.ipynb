{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99ad5363-476f-4c73-a6f4-d631f8a465c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Classical Thematic Correlator Experiment... (Timestamp: 1755755813.202131, Location: Bengaluru, India)\n",
      "MongoDB connection successful.\n",
      "\n",
      "--- Discovering training candidates from MongoDB ---\n",
      "Discovered 77 total candidates: 50 'Link' (Label 1) and 27 'Co-occurrence' (Label 0).\n",
      "\n",
      "Created dataset with 53 training samples and 24 testing samples.\n",
      "\n",
      "--- Training Classical Model with Engineered Features ---\n",
      "Training complete.\n",
      "\n",
      "--- Evaluating Classical Model ---\n",
      "\n",
      "--- FINAL CLASSICAL MODEL RESULTS ---\n",
      "Accuracy (Engineered Features): 70.83%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.12      0.22         8\n",
      "           1       0.70      1.00      0.82        16\n",
      "\n",
      "    accuracy                           0.71        24\n",
      "   macro avg       0.85      0.56      0.52        24\n",
      "weighted avg       0.80      0.71      0.62        24\n",
      "\n",
      "\n",
      "MongoDB connection closed. Experiment finished.\n"
     ]
    }
   ],
   "source": [
    "# Classical Thematic Correlator Experiment\n",
    "# Objective: Classify documents describing a thematic link using engineered features.\n",
    "#\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- Imports for this experiment ---\n",
    "from pymongo import MongoClient\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Define the core concepts for our experiment\n",
    "IMMUNE_KEYWORDS = [\"immune\", \"cytokines\", \"t-cells\", \"inflammation\", \"inflammatory\"]\n",
    "NEURO_KEYWORDS = [\"neuro\", \"alzheimer's\", \"parkinson's\", \"neurons\", \"neurodegenerative\"]\n",
    "LINKING_WORDS = [\"factor\", \"driven\", \"progression\", \"connect\", \"link\", \"cause\", \"pathway\", \"role\"]\n",
    "RANDOM_SEED = 1337\n",
    "\n",
    "# ==============================================================================\n",
    "#           PART 1: DYNAMIC DATASET CREATION FROM MONGODB\n",
    "# ==============================================================================\n",
    "\n",
    "def discover_training_candidates(collection, limit_per_category=50) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Queries MongoDB to find documents for our thematic link experiment.\"\"\"\n",
    "    print(\"\\n--- Discovering training candidates from MongoDB ---\")\n",
    "    \n",
    "    # Query for \"Thematic Link\" documents (Positive Examples)\n",
    "    query_link = {\n",
    "        \"$and\": [\n",
    "            {\"content\": {\"$regex\": \"|\".join(IMMUNE_KEYWORDS), \"$options\": \"i\"}},\n",
    "            {\"content\": {\"$regex\": \"|\".join(NEURO_KEYWORDS), \"$options\": \"i\"}},\n",
    "            {\"content\": {\"$regex\": \"|\".join(LINKING_WORDS), \"$options\": \"i\"}}\n",
    "        ]\n",
    "    }\n",
    "    link_docs = list(collection.find(query_link).limit(limit_per_category))\n",
    "    \n",
    "    # Query for \"Simple Co-occurrence\" documents (Hard Negative Examples)\n",
    "    query_co_occurrence = {\n",
    "        \"$and\": [\n",
    "            {\"content\": {\"$regex\": \"|\".join(IMMUNE_KEYWORDS), \"$options\": \"i\"}},\n",
    "            {\"content\": {\"$regex\": \"|\".join(NEURO_KEYWORDS), \"$options\": \"i\"}},\n",
    "            {\"content\": {\"$not\": {\"$regex\": \"|\".join(LINKING_WORDS), \"$options\": \"i\"}}}\n",
    "        ]\n",
    "    }\n",
    "    co_occurrence_docs = list(collection.find(query_co_occurrence).limit(limit_per_category))\n",
    "    \n",
    "    # Create the final dataset and labels\n",
    "    documents = link_docs + co_occurrence_docs\n",
    "    labels = np.array([1] * len(link_docs) + [0] * len(co_occurrence_docs))\n",
    "    \n",
    "    print(f\"Discovered {len(documents)} total candidates: {len(link_docs)} 'Link' (Label 1) and {len(co_occurrence_docs)} 'Co-occurrence' (Label 0).\")\n",
    "    return np.array(documents), labels\n",
    "\n",
    "# ==============================================================================\n",
    "#           PART 2: THE CLASSICAL LINK CLASSIFIER\n",
    "# ==============================================================================\n",
    "\n",
    "class ClassicalLinkClassifier:\n",
    "    def __init__(self, random_seed=RANDOM_SEED):\n",
    "        self.model = SGDClassifier(loss='log_loss', random_state=random_seed)\n",
    "    \n",
    "    def _extract_link_features(self, document: dict) -> np.ndarray:\n",
    "        \"\"\"Extracts manually engineered features to detect a 'link'.\"\"\"\n",
    "        doc_text = (document.get(\"title\", \"\") + \" \" + document.get(\"content\", \"\")).lower()\n",
    "        doc_words = doc_text.split()\n",
    "        \n",
    "        # Feature 1: Presence of linking words\n",
    "        has_linking_words = 1.0 if any(word in doc_words for word in LINKING_WORDS) else 0.0\n",
    "        \n",
    "        # Feature 2 & 3: Presence of concept keywords\n",
    "        immune_present = 1.0 if any(word in doc_words for word in IMMUNE_KEYWORDS) else 0.0\n",
    "        neuro_present = 1.0 if any(word in doc_words for word in NEURO_KEYWORDS) else 0.0\n",
    "        \n",
    "        return np.array([has_linking_words, immune_present, neuro_present])\n",
    "\n",
    "    def train(self, X_train_docs, y_train):\n",
    "        print(\"\\n--- Training Classical Model with Engineered Features ---\")\n",
    "        X_train_features = np.array([self._extract_link_features(doc) for doc in X_train_docs])\n",
    "        self.model.fit(X_train_features, y_train)\n",
    "        print(\"Training complete.\")\n",
    "\n",
    "    def predict(self, X_test_docs):\n",
    "        print(\"\\n--- Evaluating Classical Model ---\")\n",
    "        X_test_features = np.array([self._extract_link_features(doc) for doc in X_test_docs])\n",
    "        return self.model.predict(X_test_features)\n",
    "\n",
    "# ==============================================================================\n",
    "#           PART 3: MAIN EXPERIMENT EXECUTION\n",
    "# ==============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Starting Classical Thematic Correlator Experiment... (Timestamp: {time.time()}, Location: Bengaluru, India)\")\n",
    "    load_dotenv()\n",
    "    mongo_uri = os.getenv(\"MONGO_URI\")\n",
    "    db_name = os.getenv(\"MONGO_DB\")\n",
    "    collection_name = os.getenv(\"MONGO_COLLECTION\")\n",
    "    if not all([mongo_uri, db_name, collection_name]):\n",
    "        raise ValueError(\"MongoDB credentials not found in .env file.\")\n",
    "        \n",
    "    mongo_client = MongoClient(mongo_uri)\n",
    "    db = mongo_client[db_name]\n",
    "    collection = db[collection_name]\n",
    "    print(\"MongoDB connection successful.\")\n",
    "\n",
    "    # 1. Create dataset from the database\n",
    "    documents, labels = discover_training_candidates(collection, limit_per_category=50)\n",
    "    \n",
    "    if len(np.unique(labels)) < 2:\n",
    "        print(\"Could not find enough documents for both classes. Experiment requires 'Link' and 'Co-occurrence' docs. Aborting.\")\n",
    "    else:\n",
    "        # 2. Split data for training and testing\n",
    "        X_train_docs, X_test_docs, y_train, y_test = train_test_split(\n",
    "            documents, labels, test_size=0.3, random_state=RANDOM_SEED, stratify=labels\n",
    "        )\n",
    "        print(f\"\\nCreated dataset with {len(y_train)} training samples and {len(y_test)} testing samples.\")\n",
    "\n",
    "        # 3. Run Classical Experiment\n",
    "        classical_model = ClassicalLinkClassifier()\n",
    "        classical_model.train(X_train_docs, y_train)\n",
    "        classical_preds = classical_model.predict(X_test_docs)\n",
    "        classical_accuracy = accuracy_score(y_test, classical_preds)\n",
    "        \n",
    "        print(\"\\n--- FINAL CLASSICAL MODEL RESULTS ---\")\n",
    "        print(f\"Accuracy (Engineered Features): {classical_accuracy:.2%}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, classical_preds))\n",
    "    \n",
    "    mongo_client.close()\n",
    "    print(\"\\nMongoDB connection closed. Experiment finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7772747-02fa-4462-b7ab-4dabc9056a54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Quantum Thematic Correlator Experiment... (Timestamp: 1755761709.2004569, Location: Bengaluru, India)\n",
      "Service initialized for instance 'ibm_quantum'.\n",
      "MongoDB connection successful.\n",
      "\n",
      "--- Discovering training candidates from MongoDB ---\n",
      "Discovered 77 total candidates: 50 'Link' (Label 1) and 27 'Co-occurrence' (Label 0).\n",
      "\n",
      "Created dataset with 53 training samples and 24 testing samples.\n",
      "\n",
      "--- Initializing Quantum Link Classifier for 'ibm_brisbane' ---\n",
      "Real hardware detected. The backend will apply its default error correction.\n",
      "Initializing Sampler with V2 options...\n",
      "Sampler initialized successfully.\n",
      "Using a noise-resilient ansatz with reps=2.\n",
      "Abstract PQC created. Transpiling for hardware compatibility...\n",
      "Transpilation complete.\n",
      "\n",
      "--- Starting Manual Training (5 optimizer iterations) ---\n",
      "\n",
      "--- Optimizer Iteration: 1/5 ---\n",
      "Submitting job with 53 PUBs...\n",
      "Job submitted with ID: d2jcoffa6cjs73f8ugk0. Waiting for results...\n",
      "Results received.\n",
      "  Avg. Loss for Iteration 1: 0.3290\n",
      "\n",
      "--- Optimizer Iteration: 2/5 ---\n",
      "Submitting job with 53 PUBs...\n",
      "Job submitted with ID: d2jcp0sg59ks73c3k510. Waiting for results...\n",
      "Results received.\n",
      "  Avg. Loss for Iteration 2: 0.3288\n",
      "\n",
      "--- Optimizer Iteration: 3/5 ---\n",
      "Submitting job with 53 PUBs...\n",
      "Job submitted with ID: d2jcpi8hsgmc73b33aqg. Waiting for results...\n",
      "Results received.\n",
      "  Avg. Loss for Iteration 3: 0.2893\n",
      "\n",
      "--- Optimizer Iteration: 4/5 ---\n",
      "Submitting job with 53 PUBs...\n",
      "Job submitted with ID: d2jcq3uhb60s73cruoeg. Waiting for results...\n",
      "Results received.\n",
      "  Avg. Loss for Iteration 4: 0.3684\n",
      "\n",
      "--- Optimizer Iteration: 5/5 ---\n",
      "Submitting job with 53 PUBs...\n",
      "Job submitted with ID: d2jcqlghsgmc73b33bq0. Waiting for results...\n",
      "Results received.\n",
      "  Avg. Loss for Iteration 5: 0.2824\n",
      "\n",
      "--- Training Complete ---\n",
      "\n",
      "--- Evaluating Quantum Model ---\n",
      "Submitting prediction job with 24 PUBs...\n",
      "Job submitted with ID: d2jcr8kg59ks73c3k72g. Waiting for results...\n",
      "Prediction results received.\n",
      "\n",
      "--- FINAL QUANTUM MODEL RESULTS ---\n",
      "Backend: ibm_brisbane\n",
      "Accuracy (Simple Semantic Features): 62.50%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.65      0.94      0.77        16\n",
      "\n",
      "    accuracy                           0.62        24\n",
      "   macro avg       0.33      0.47      0.38        24\n",
      "weighted avg       0.43      0.62      0.51        24\n",
      "\n",
      "\n",
      "MongoDB connection closed. Experiment finished.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Quantum Thematic Correlator Experiment\n",
    "# Final Authoritative Version with Error Mitigation and Hardware Optimization\n",
    "#\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- Data and NLP Imports ---\n",
    "from pymongo import MongoClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# --- Modern Qiskit Imports for the Open Plan ---\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService, SamplerV2 as Sampler\n",
    "# --- CORRECTED IMPORT: Import the specific options class for clarity and validation ---\n",
    "from qiskit_ibm_runtime.options import SamplerOptions\n",
    "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
    "from qiskit.circuit import QuantumCircuit\n",
    "from qiskit_algorithms.optimizers import COBYLA\n",
    "from qiskit_algorithms.utils import algorithm_globals\n",
    "from qiskit.compiler import transpile\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "algorithm_globals.random_seed = 1337\n",
    "IMMUNE_KEYWORDS = [\"immune\", \"cytokines\", \"t-cells\", \"inflammation\", \"inflammatory\"]\n",
    "NEURO_KEYWORDS = [\"neuro\", \"alzheimer's\", \"parkinson's\", \"neurons\", \"neurodegenerative\"]\n",
    "LINKING_WORDS = [\"factor\", \"driven\", \"progression\", \"connect\", \"link\", \"cause\", \"pathway\", \"role\"]\n",
    "\n",
    "def discover_training_candidates(collection, limit_per_category=50) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Queries MongoDB to find documents for our thematic link experiment.\"\"\"\n",
    "    print(\"\\n--- Discovering training candidates from MongoDB ---\")\n",
    "    query_link = {\n",
    "        \"$and\": [\n",
    "            {\"content\": {\"$regex\": \"|\".join(IMMUNE_KEYWORDS), \"$options\": \"i\"}},\n",
    "            {\"content\": {\"$regex\": \"|\".join(NEURO_KEYWORDS), \"$options\": \"i\"}},\n",
    "            {\"content\": {\"$regex\": \"|\".join(LINKING_WORDS), \"$options\": \"i\"}}\n",
    "        ]\n",
    "    }\n",
    "    link_docs = list(collection.find(query_link).limit(limit_per_category))\n",
    "    \n",
    "    query_co_occurrence = {\n",
    "        \"$and\": [\n",
    "            {\"content\": {\"$regex\": \"|\".join(IMMUNE_KEYWORDS), \"$options\": \"i\"}},\n",
    "            {\"content\": {\"$regex\": \"|\".join(NEURO_KEYWORDS), \"$options\": \"i\"}},\n",
    "            {\"content\": {\"$not\": {\"$regex\": \"|\".join(LINKING_WORDS), \"$options\": \"i\"}}}\n",
    "        ]\n",
    "    }\n",
    "    co_occurrence_docs = list(collection.find(query_co_occurrence).limit(limit_per_category))\n",
    "\n",
    "    documents = link_docs + co_occurrence_docs\n",
    "    labels = np.array([1] * len(link_docs) + [0] * len(co_occurrence_docs))\n",
    "    \n",
    "    print(f\"Discovered {len(documents)} total candidates: {len(link_docs)} 'Link' (Label 1) and {len(co_occurrence_docs)} 'Co-occurrence' (Label 0).\")\n",
    "    return np.array(documents), labels\n",
    "\n",
    "\n",
    "class QuantumLinkClassifier:\n",
    "    \"\"\"\n",
    "    A quantum classifier refactored to use the manual, session-less pattern\n",
    "    required for the IBM Quantum Open Plan. Includes hardware-aware optimizations.\n",
    "    \"\"\"\n",
    "    def __init__(self, service, backend_name=\"ibm_brisbane\"):\n",
    "        print(f\"\\n--- Initializing Quantum Link Classifier for '{backend_name}' ---\")\n",
    "        \n",
    "        # --- 1. Initialize Primitives and Backend ---\n",
    "        self.backend_name = backend_name\n",
    "        self.shots = 4096 \n",
    "        backend_object = service.backend(self.backend_name)\n",
    "        \n",
    "        # --- CORRECTED: Initialize the SamplerOptions class ---\n",
    "        # This provides a structured way to set options and avoids validation errors.\n",
    "        options = SamplerOptions()\n",
    "        \n",
    "        # --- NOTE: SamplerV2 does NOT support the 'resilience_level' option. ---\n",
    "        # This feature is specific to EstimatorV2 for mitigating errors in expectation values.\n",
    "        # When using SamplerV2, the backend may still apply some default level of readout\n",
    "        # error correction, but the advanced mitigation techniques controlled by\n",
    "        # resilience_level are not available. The code block attempting to set this\n",
    "        # has been removed to fix the error.\n",
    "        if not backend_object.configuration().simulator:\n",
    "            print(\"Real hardware detected. The backend will apply its default error correction.\")\n",
    "        \n",
    "        print(\"Initializing Sampler with V2 options...\")\n",
    "        # Pass the structured options object to the Sampler\n",
    "        self.sampler = Sampler(mode=backend_object, options=options)\n",
    "        print(\"Sampler initialized successfully.\")\n",
    "\n",
    "        # --- 2. Create and Transpile the Quantum Circuit ---\n",
    "        self.feature_dim = 2\n",
    "        feature_map = ZZFeatureMap(feature_dimension=self.feature_dim, reps=2)\n",
    "        \n",
    "        # --- STRATEGY: Simplify the Ansatz for Noise Resilience ---\n",
    "        print(\"Using a noise-resilient ansatz with reps=2.\")\n",
    "        self.ansatz = RealAmplitudes(num_qubits=self.feature_dim, reps=2)\n",
    "        \n",
    "        pqc = QuantumCircuit(self.feature_dim)\n",
    "        pqc.compose(feature_map, inplace=True)\n",
    "        pqc.compose(self.ansatz, inplace=True)\n",
    "        pqc.measure_all(inplace=True) \n",
    "        \n",
    "        print(\"Abstract PQC created. Transpiling for hardware compatibility...\")\n",
    "        # --- STRATEGY: Use optimization_level=1 for hardware to prioritize noise resilience over aggressive gate reduction ---\n",
    "        self.isa_pqc = transpile(pqc, backend=backend_object, optimization_level=1)\n",
    "        print(\"Transpilation complete.\")\n",
    "        \n",
    "        # --- 3. Classical Components ---\n",
    "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.concept_A_embedding = self.embedding_model.encode([\"immune system response inflammation\"])\n",
    "        self.concept_B_embedding = self.embedding_model.encode([\"neurodegenerative disease alzheimer's parkinson's\"])\n",
    "        self.optimal_weights = None\n",
    "\n",
    "    def _extract_semantic_features(self, document: dict) -> np.ndarray:\n",
    "        doc_text = document.get(\"title\", \"\") + \" \" + document.get(\"content\", \"\")\n",
    "        if not doc_text.strip(): return np.array([0.0, 0.0])\n",
    "        doc_embedding = self.embedding_model.encode([doc_text])\n",
    "        sim_A = cosine_similarity(doc_embedding, self.concept_A_embedding)[0][0]\n",
    "        sim_B = cosine_similarity(doc_embedding, self.concept_B_embedding)[0][0]\n",
    "        return np.array([sim_A, sim_B])\n",
    "\n",
    "    def train(self, X_train_docs, y_train, maxiter=5):\n",
    "        print(f\"\\n--- Starting Manual Training ({maxiter} optimizer iterations) ---\")\n",
    "        X_train_features = np.array([self._extract_semantic_features(doc) for doc in X_train_docs])\n",
    "        optimizer = COBYLA(maxiter=maxiter)\n",
    "        \n",
    "        iteration_count = 0\n",
    "        def objective_function(weights):\n",
    "            nonlocal iteration_count\n",
    "            iteration_count += 1\n",
    "            print(f\"\\n--- Optimizer Iteration: {iteration_count}/{maxiter} ---\")\n",
    "            \n",
    "            # A PUB (Primitive Unified Bloc) is a tuple of (circuit, parameter_values)\n",
    "            pubs = [(self.isa_pqc, np.concatenate((x_i, weights))) for x_i in X_train_features]\n",
    "            \n",
    "            print(f\"Submitting job with {len(pubs)} PUBs...\")\n",
    "            # For SamplerV2, shots is an argument to the run() method.\n",
    "            job = self.sampler.run(pubs, shots=self.shots)\n",
    "            print(f\"Job submitted with ID: {job.job_id()}. Waiting for results...\")\n",
    "            result = job.result()\n",
    "            print(\"Results received.\")\n",
    "            \n",
    "            total_loss = 0\n",
    "            for i, y_true in enumerate(y_train):\n",
    "                pub_result = result[i]\n",
    "                # Access measurement outcomes via the 'meas' data field\n",
    "                outcomes = pub_result.data.meas.array \n",
    "                # Calculate probability of '1' state (assuming standard Z measurement on the first qubit)\n",
    "                prob_1 = np.mean(outcomes % 2)\n",
    "                total_loss += (prob_1 - y_true)**2\n",
    "            \n",
    "            avg_loss = total_loss / len(y_train)\n",
    "            print(f\"  Avg. Loss for Iteration {iteration_count}: {avg_loss:.4f}\")\n",
    "            return avg_loss\n",
    "\n",
    "        initial_weights = np.random.uniform(0, 2 * np.pi, self.ansatz.num_parameters)\n",
    "        opt_result = optimizer.minimize(objective_function, initial_weights)\n",
    "        self.optimal_weights = opt_result.x\n",
    "        print(\"\\n--- Training Complete ---\")\n",
    "\n",
    "    def predict(self, X_test_docs):\n",
    "        print(\"\\n--- Evaluating Quantum Model ---\")\n",
    "        if self.optimal_weights is None:\n",
    "            raise RuntimeError(\"Model must be trained first.\")\n",
    "        \n",
    "        X_test_features = np.array([self._extract_semantic_features(doc) for doc in X_test_docs])\n",
    "        pubs = [(self.isa_pqc, np.concatenate((x_i, self.optimal_weights))) for x_i in X_test_features]\n",
    "        \n",
    "        print(f\"Submitting prediction job with {len(pubs)} PUBs...\")\n",
    "        # For SamplerV2, shots is an argument to the run() method.\n",
    "        job = self.sampler.run(pubs, shots=self.shots)\n",
    "        print(f\"Job submitted with ID: {job.job_id()}. Waiting for results...\")\n",
    "        result = job.result()\n",
    "        print(\"Prediction results received.\")\n",
    "        \n",
    "        predictions = []\n",
    "        for pub_result in result:\n",
    "            outcomes = pub_result.data.meas.array\n",
    "            prob_1 = np.mean(outcomes % 2)\n",
    "            predictions.append(1 if prob_1 > 0.5 else 0)\n",
    "            \n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Starting Quantum Thematic Correlator Experiment... (Timestamp: {time.time()}, Location: Bengaluru, India)\")\n",
    "    load_dotenv()\n",
    "    \n",
    "    # --- EXPERIMENT CONFIGURATION ---\n",
    "    # 1. To get a NOISELESS BASELINE, use \"ibm_qasm_simulator\" and a high maxiter.\n",
    "    # 2. To run on HARDWARE, use a real backend like \"ibm_brisbane\" and a low maxiter.\n",
    "    BACKEND_NAME = \"ibm_brisbane\" \n",
    "    \n",
    "    if \"simulator\" in BACKEND_NAME:\n",
    "        MAX_ITERATIONS = 50 # More iterations for the fast, ideal simulator\n",
    "    else:\n",
    "        MAX_ITERATIONS = 5  # Fewer iterations for the slower hardware queue\n",
    "\n",
    "    # --- Service Initialization ---\n",
    "    # The 'instance' is a specific project group. 'ibm-q/open/main' is the standard for the open plan.\n",
    "    # NOTE: The token below is a placeholder and has been kept as-is from the original script.\n",
    "    # In a real scenario, this should be loaded securely, e.g., from environment variables.\n",
    "    instance_name = \"ibm_quantum\" # A common instance for open plan users\n",
    "    service = QiskitRuntimeService(\n",
    "        channel='ibm_quantum_platform',\n",
    "        token=\"YOUR_IBM_KEY\",\n",
    "        instance=instance_name\n",
    "    )\n",
    "    # --- CORRECTED: Use the variable holding the instance name for the print statement ---\n",
    "    print(f\"Service initialized for instance '{instance_name}'.\")\n",
    "\n",
    "    # --- MongoDB Connection ---\n",
    "    # Make sure your .env file has MONGO_URI, MONGO_DB, and MONGO_COLLECTION set\n",
    "    mongo_client = MongoClient(os.getenv(\"MONGO_URI\"))\n",
    "    db = mongo_client[os.getenv(\"MONGO_DB\")]\n",
    "    collection = db[os.getenv(\"MONGO_COLLECTION\")]\n",
    "    print(\"MongoDB connection successful.\")\n",
    "\n",
    "    documents, labels = discover_training_candidates(collection, limit_per_category=50)\n",
    "\n",
    "    if len(np.unique(labels)) < 2:\n",
    "        print(\"Could not find enough docs for both classes. Aborting.\")\n",
    "    else:\n",
    "        X_train_docs, X_test_docs, y_train, y_test = train_test_split(\n",
    "            documents, labels, test_size=0.3, random_state=1337, stratify=labels\n",
    "        )\n",
    "        print(f\"\\nCreated dataset with {len(y_train)} training samples and {len(y_test)} testing samples.\")\n",
    "\n",
    "        # --- Run Quantum Experiment ---\n",
    "        quantum_model = QuantumLinkClassifier(service=service, backend_name=BACKEND_NAME)\n",
    "        quantum_model.train(X_train_docs, y_train, maxiter=MAX_ITERATIONS)\n",
    "        quantum_preds = quantum_model.predict(X_test_docs)\n",
    "        \n",
    "        print(\"\\n--- FINAL QUANTUM MODEL RESULTS ---\")\n",
    "        print(f\"Backend: {BACKEND_NAME}\")\n",
    "        print(f\"Accuracy (Simple Semantic Features): {accuracy_score(y_test, quantum_preds):.2%}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, quantum_preds))\n",
    "\n",
    "    mongo_client.close()\n",
    "    print(\"\\nMongoDB connection closed. Experiment finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19dc8883-3e9a-4576-ab1b-56f2dbdf7c44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Experiment Report: A Comparison of Classical and Quantum Thematic Correlators\\nDate: Thursday, August 21, 2025\\nLocation: Bengaluru, Karnataka, India\\nAuthor: Anirudh R\\nProject Status: Complete\\n\\nExecutive Summary\\nThis report details the results of a head-to-head experiment comparing a classical machine learning\\nmodel with engineered features against a Variational Quantum Classifier (VQC) with simple semantic features.\\nBoth models were tasked with identifying documents that describe a thematic link between two concepts\\n(\"Immune System\" and \"Neurodegenerative Disease\"). The dataset was dynamically generated from a MongoDB\\ndatabase, resulting in an imbalanced set of 77 documents.\\n\\nThe results show that the classical model achieved a significantly higher accuracy (70.83%) compared to\\nthe quantum model (62.50%). Analysis of the classification reports reveals that both models struggled with\\nthe imbalanced dataset, but the classical model learned a useful, albeit biased, decision boundary. The\\nquantum model, running on the ibm_brisbane hardware, failed to learn a meaningful pattern and resorted to\\npredicting the majority class. The primary conclusion is that for this task, the manually engineered features\\nprovided a much stronger signal than the quantum feature map was able to extract from simple semantic inputs.\\n\\n1. Experiment Objective\\nThe goal was to test if a quantum re-ranker, using simple semantic features, could outperform a classical one\\nthat required complex, manual feature engineering. The task was to classify documents as either describing a\\nthematic link (Label 1) or merely containing a co-occurrence of keywords (Label 0).\\n\\n2. Methodology\\nDataset Discovery: A dataset was dynamically created by querying a MongoDB database. This process discovered\\n77 total candidate documents.\\n\\n50 documents were classified as \"Link\" (Label 1).\\n\\n27 documents were classified as \"Co-occurrence\" (Label 0).\\n\\nDataset Split: The 77 documents were split into a training set with 53 samples and a testing set with 24 samples.\\n\\nClassical Model: This model used manually engineered features to make its predictions.\\n\\nQuantum Model: This model used simple semantic features. It was executed on the ibm_brisbane quantum processor.\\nThe model was trained for 5 optimizer iterations, and the training log showed a fluctuating loss that started\\nat 0.3290 and ended at 0.2824.\\n\\n3. Results\\nThe performance of both models on the 24-sample test set is detailed below.\\n\\nMetric\\tClass\\tClassical Model (Engineered Features)\\tQuantum Model (Simple Semantic Features)\\nAccuracy\\tOverall\\t70.83%\\t62.50%\\nPrecision\\t0 (Irrelevant)\\t1.00\\t0.00\\n1 (Relevant)\\t0.70\\t0.65\\nRecall\\t0 (Irrelevant)\\t0.12\\t0.00\\n1 (Relevant)\\t1.00\\t0.94\\nF1-Score\\t0 (Irrelevant)\\t0.22\\t0.00\\n1 (Relevant)\\t0.82\\t0.77\\nSupport\\t0 (Irrelevant)\\t8 samples\\t8 samples\\n1 (Relevant)\\t16 samples\\t16 samples\\n\\n4. Analysis and Interpretation\\nClassical Model Performance: The classical model achieved a respectable accuracy of 70.83%. However, its performance\\nwas highly skewed. It successfully identified 100% of the relevant \"Link\" documents (recall=1.00). To do this, it\\nmisclassified most of the irrelevant documents, only correctly identifying 12% of them (recall=0.12). This indicates\\nthe model learned a strong bias to predict the majority class (Label 1).\\n\\nQuantum Model Performance: The quantum model\\'s accuracy was lower at 62.50%. Its classification report shows a complete\\nfailure to identify any irrelevant documents, with precision and recall scores of 0.00 for Class 0. This performance is\\nstatistically consistent with a strategy of simply guessing the majority class (Label 1) for every sample, which would\\nyield an accuracy of 16/24, or 66.7%. The model failed to learn a useful decision boundary from the simple semantic\\nfeatures when faced with hardware noise and an imbalanced dataset.\\n\\n5. Conclusion\\nThe classical model with manually engineered features was the clear winner in this experiment. The key insight from this\\nresult is that the quality and informational content of the features were the deciding factor. The sophisticated,\\nhuman-guided features used by the classical model provided a much stronger learning signal than the quantum feature map\\nwas able to extract from simple semantic similarity scores. This result underscores the significant challenge of automated\\nfeature extraction in the NISQ era and highlights the effectiveness of well-designed classical approaches.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Experiment Report: A Comparison of Classical and Quantum Thematic Correlators\n",
    "Date: Thursday, August 21, 2025\n",
    "Location: Bengaluru, Karnataka, India\n",
    "Author: Anirudh R\n",
    "Project Status: Complete\n",
    "\n",
    "Executive Summary\n",
    "This report details the results of a head-to-head experiment comparing a classical machine learning\n",
    "model with engineered features against a Variational Quantum Classifier (VQC) with simple semantic features.\n",
    "Both models were tasked with identifying documents that describe a thematic link between two concepts\n",
    "(\"Immune System\" and \"Neurodegenerative Disease\"). The dataset was dynamically generated from a MongoDB\n",
    "database, resulting in an imbalanced set of 77 documents.\n",
    "\n",
    "The results show that the classical model achieved a significantly higher accuracy (70.83%) compared to\n",
    "the quantum model (62.50%). Analysis of the classification reports reveals that both models struggled with\n",
    "the imbalanced dataset, but the classical model learned a useful, albeit biased, decision boundary. The\n",
    "quantum model, running on the ibm_brisbane hardware, failed to learn a meaningful pattern and resorted to\n",
    "predicting the majority class. The primary conclusion is that for this task, the manually engineered features\n",
    "provided a much stronger signal than the quantum feature map was able to extract from simple semantic inputs.\n",
    "\n",
    "1. Experiment Objective\n",
    "The goal was to test if a quantum re-ranker, using simple semantic features, could outperform a classical one\n",
    "that required complex, manual feature engineering. The task was to classify documents as either describing a\n",
    "thematic link (Label 1) or merely containing a co-occurrence of keywords (Label 0).\n",
    "\n",
    "2. Methodology\n",
    "Dataset Discovery: A dataset was dynamically created by querying a MongoDB database. This process discovered\n",
    "77 total candidate documents.\n",
    "\n",
    "50 documents were classified as \"Link\" (Label 1).\n",
    "\n",
    "27 documents were classified as \"Co-occurrence\" (Label 0).\n",
    "\n",
    "Dataset Split: The 77 documents were split into a training set with 53 samples and a testing set with 24 samples.\n",
    "\n",
    "Classical Model: This model used manually engineered features to make its predictions.\n",
    "\n",
    "Quantum Model: This model used simple semantic features. It was executed on the ibm_brisbane quantum processor.\n",
    "The model was trained for 5 optimizer iterations, and the training log showed a fluctuating loss that started\n",
    "at 0.3290 and ended at 0.2824.\n",
    "\n",
    "3. Results\n",
    "The performance of both models on the 24-sample test set is detailed below.\n",
    "\n",
    "Metric\tClass\tClassical Model (Engineered Features)\tQuantum Model (Simple Semantic Features)\n",
    "Accuracy\tOverall\t70.83%\t62.50%\n",
    "Precision\t0 (Irrelevant)\t1.00\t0.00\n",
    "1 (Relevant)\t0.70\t0.65\n",
    "Recall\t0 (Irrelevant)\t0.12\t0.00\n",
    "1 (Relevant)\t1.00\t0.94\n",
    "F1-Score\t0 (Irrelevant)\t0.22\t0.00\n",
    "1 (Relevant)\t0.82\t0.77\n",
    "Support\t0 (Irrelevant)\t8 samples\t8 samples\n",
    "1 (Relevant)\t16 samples\t16 samples\n",
    "\n",
    "4. Analysis and Interpretation\n",
    "Classical Model Performance: The classical model achieved a respectable accuracy of 70.83%. However, its performance\n",
    "was highly skewed. It successfully identified 100% of the relevant \"Link\" documents (recall=1.00). To do this, it\n",
    "misclassified most of the irrelevant documents, only correctly identifying 12% of them (recall=0.12). This indicates\n",
    "the model learned a strong bias to predict the majority class (Label 1).\n",
    "\n",
    "Quantum Model Performance: The quantum model's accuracy was lower at 62.50%. Its classification report shows a complete\n",
    "failure to identify any irrelevant documents, with precision and recall scores of 0.00 for Class 0. This performance is\n",
    "statistically consistent with a strategy of simply guessing the majority class (Label 1) for every sample, which would\n",
    "yield an accuracy of 16/24, or 66.7%. The model failed to learn a useful decision boundary from the simple semantic\n",
    "features when faced with hardware noise and an imbalanced dataset.\n",
    "\n",
    "5. Conclusion\n",
    "The classical model with manually engineered features was the clear winner in this experiment. The key insight from this\n",
    "result is that the quality and informational content of the features were the deciding factor. The sophisticated,\n",
    "human-guided features used by the classical model provided a much stronger learning signal than the quantum feature map\n",
    "was able to extract from simple semantic similarity scores. This result underscores the significant challenge of automated\n",
    "feature extraction in the NISQ era and highlights the effectiveness of well-designed classical approaches.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f31215c-2d69-459d-8df1-c0236c2f5118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
